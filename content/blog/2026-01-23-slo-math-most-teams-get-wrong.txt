---
title: "The SLO Math Most Teams Get Wrong"
date: "2026-01-23"
author: Dylan
description: "Common SLO mistakes and how to fix them. Lessons from implementing service level objectives at scale."
tags:
  - SRE
  - SLOs
  - Observability
category: Technical
draft: false
---

SLOs sound simple: pick a metric, set a target, track your error budget. In practice, most teams get the math wrong in ways that make their SLOs useless.

## The availability trap

Everyone starts with availability. "We want 99.9% uptime." The problem isn't the number. It's what counts against it.

I've watched teams celebrate hitting their availability targets while ignoring a glaring hole: planned maintenance. They're measuring availability but not spending any of it on upgrades, patches, or migrations. The SLO looks great on paper, but it's fiction.

If you're not burning error budget on planned work, you're either lying to yourself about your reliability or you're not doing enough maintenance. Both are problems.

The fix: count planned downtime against your budget. It forces honest conversations about how much reliability you're actually delivering versus how much you're claiming.

## Error budgets that ignore dependencies

I've seen teams set their error budgets in isolation, completely ignoring the availability of their dependencies. This is backwards.

Here's the math that gets missed: if your service depends on three upstream services each running at 99.9%, your theoretical ceiling is around 99.7%. That's assuming your own code adds zero failures. Setting a 99.99% SLO when your dependencies can only deliver 99.7% isn't ambitious. It's a fantasy.

Before setting your error budget, map your dependency chain. Your SLO can't be tighter than the product of your dependencies' SLOs. Start there and work backwards.

## Latency percentiles: p50 vs p99

Teams obsess over average latency. Averages hide outliers. A p50 of 100ms means nothing if your p99 is 10 seconds.

The users hitting that p99 are real people. They're often your power users, the ones making complex queries or loading large datasets. The workflows that actually matter to your business.

Track at least p50, p95, and p99. The gap between them tells you more about your system's behavior than any single number. A small gap means predictable performance. A large gap means you have tail latency problems that averages will never surface.

## The aggregation problem

SLOs at the service level hide problems. A service running at 99.9% aggregate might have one customer segment at 95%.

This happens more than people admit. Your overall metrics look healthy while a specific region or customer tier is suffering. The aggregate math washes out the signal.

The solution: slice your SLOs by dimensions that matter. Customer tier. Region. Endpoint. One number for the whole service isn't enough. (I built the [SLO Calculator](/projects/slo-tool) partly to make this kind of slicing easier to think through.)

## Setting targets that mean something

"What should our SLO be?" Wrong question. The right question: "What reliability do our users actually need?"

My approach: start low, ratchet higher as confidence builds. A 99% SLO you can actually hit teaches you more than a 99.99% SLO you immediately blow through. You learn what breaks, what's hard to maintain, what your system is actually capable of.

Once you're consistently hitting your target with room to spare, tighten it. This builds credibility with your users and your team. An SLO that keeps getting violated becomes noise that everyone ignores.

## When to break the SLO

Counterintuitive: sometimes you should intentionally burn error budget. The budget exists to enable decisions, not to be hoarded.

Sometimes you have to ship fast. A competitive deadline, a security patch, a feature that unlocks a major customer. These are valid reasons to accept reliability risk as a tradeoff.

The key is making it explicit. "We're choosing to ship this knowing it might burn 20% of our monthly budget" is a healthy conversation. Accidentally burning budget because you didn't think about it is not.

## SLOs as promises

SLOs are a communication tool.

Their real value is helping the services that depend on you understand what they're building their foundation on. When downstream teams know your SLO, they can make informed decisions about redundancy, fallbacks, and their own targets.

A published SLO is a promise. It sets expectations. That clarity is what makes the whole system work.

